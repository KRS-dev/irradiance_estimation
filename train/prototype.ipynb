{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36685db-41a6-4a16-90c0-b65b5b388fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import wandb\n",
    "import xarray\n",
    "from dataset.dataset import ImageDataset, valid_test_split, SeviriDataset, pickle_write\n",
    "from dataset.station_dataset import GroundstationDataset\n",
    "from dataset.normalization import MinMax, ZeroMinMax\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.plugins.environments import SLURMEnvironment\n",
    "from lightning.pytorch.utilities import rank_zero_only\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from models.ConvResNet_Jiang import ConvResNet, ConvResNet_dropout\n",
    "from models.LightningModule import LitEstimator, LitEstimatorPoint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from pytorch_lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from utils.plotting import best_worst_plot, prediction_error_plot\n",
    "from utils.etc import benchmark\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "dask.config.set(scheduler='synchronous')\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c59f22a-d816-4700-81ea-d0144b7f74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"patch_size\": {\n",
    "        \"x\": 15,\n",
    "        \"y\": 15,\n",
    "        \"stride_x\": 1,\n",
    "        \"stride_y\": 1,\n",
    "    },\n",
    "    \"x_vars\": [\n",
    "        \"channel_1\",\n",
    "        \"channel_2\",\n",
    "        \"channel_3\",\n",
    "        \"channel_4\",\n",
    "        \"channel_5\",\n",
    "        \"channel_6\",\n",
    "        \"channel_7\",\n",
    "        \"channel_8\",\n",
    "        \"channel_9\",\n",
    "        \"channel_10\",\n",
    "        \"channel_11\",\n",
    "        \"DEM\",\n",
    "    ],\n",
    "    \"y_vars\": [\"SIS\"],\n",
    "    \"x_features\": [\"dayofyear\", \"lat\", \"lon\", 'SZA', \"AZI\",],\n",
    "    \"transform\": ZeroMinMax(),\n",
    "    \"target_transform\": ZeroMinMax(),\n",
    "    # Compute related\n",
    "    'num_workers': 12,\n",
    "    'ACCELERATOR': \"gpu\",\n",
    "    'DEVICES': -1,\n",
    "    'NUM_NODES': 32,\n",
    "    'STRATEGY': \"ddp\",\n",
    "    'PRECISION': \"32\",\n",
    "    'EarlyStopping': {'patience':5},\n",
    "}\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88391c0c-d8cb-4de3-948a-a584b19b8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.EarlyStopping['patience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2352d3-a607-47ba-b44e-1c7fc49af7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dem load : 1.594 seconds\n"
     ]
    }
   ],
   "source": [
    "seviri = xarray.open_zarr(\"/scratch/snx3000/kschuurm/ZARR/SEVIRI_new.zarr\")\n",
    "solarpos = xarray.open_zarr(\"/scratch/snx3000/kschuurm/ZARR/SOLARPOS_new.zarr\")\n",
    "sarah = xarray.open_zarr(\"/scratch/snx3000/kschuurm/ZARR/SARAH3_new.zarr\")\n",
    "with benchmark('dem load'):\n",
    "    dem = xarray.open_zarr(\"/scratch/snx3000/kschuurm/ZARR/DEM.zarr\").fillna(0).load()\n",
    "a = seviri.channel_data.to_dataset(dim='channel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3f4c87-52dc-4cfd-9dd0-86a51cc64c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/snx3000/kschuurm/lightning/lib/python3.9/site-packages/distributed/client.py:3162: Sending large graph of size 35.30 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any : 957.176 seconds\n"
     ]
    }
   ],
   "source": [
    "with benchmark('any'):\n",
    "    idx = seviri.channel_data.isnull().any(dim=['x','y','channel']).compute()\n",
    "    idx_val = idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1559e70-f8d5-44d0-83cb-fdd875c5e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/snx3000/kschuurm/lightning/lib/python3.9/site-packages/distributed/client.py:3162: Sending large graph of size 37.85 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n"
     ]
    }
   ],
   "source": [
    "with benchmark('mean'):\n",
    "    idx = seviri.channel_data.isnull().mean(dim=['x','y','channel']).compute()\n",
    "    idx_val = idx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7dedd9-2cec-4b1d-9445-f48ec66546f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-01-01T00:00:00.000000000', '2016-01-01T00:15:00.000000000',\n",
       "       '2016-01-01T00:30:00.000000000', ...,\n",
       "       '2022-12-31T23:15:00.000000000', '2022-12-31T23:30:00.000000000',\n",
       "       '2022-12-31T23:45:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.time[~idx_val].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0898812-2ed0-4231-ad95-b9b81cada0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch/snx3000/kschuurm/ZARR/idxnotnan_seviri.npy', idx.time[~idx_val].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0eb1f8-7e77-4b83-b1df-0ead60e72250",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = {          \"VIS006\": \"channel_1\",\n",
    "            \"VIS008\": \"channel_2\",\n",
    "            \"IR_016\": \"channel_3\",\n",
    "            \"IR_039\": \"channel_4\",\n",
    "            \"WV_062\": \"channel_5\",\n",
    "            \"WV_073\": \"channel_6\",\n",
    "            \"IR_087\": \"channel_7\",\n",
    "            \"IR_097\": \"channel_8\",\n",
    "            \"IR_108\": \"channel_9\",\n",
    "            \"IR_120\": \"channel_10\",\n",
    "            \"IR_134\": \"channel_11\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceda5a7-6199-418a-ad3f-e6ff6e4f62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= np.random.randint(0, 400, size=1000) # lon samples\n",
    "j = np.random.randint(0, 400, size=1000) # lat samples\n",
    "\n",
    "with benchmark('sarah load'):\n",
    "    a = seviri.isel(time=0).load() # seviri like zarr dataset\n",
    "\n",
    "with benchmark('seviri rename'):\n",
    "    nms = a.channel.values\n",
    "    nms_trans = [trans[x] for x in nms]\n",
    "    a['channel'] = nms_trans\n",
    "    x_vars_available = [x for x in config.x_vars if x in nms_trans]\n",
    "    a = a.sel(channel=x_vars_available) \\\n",
    "    .rename({\n",
    "        'y':'lat',\n",
    "        'x':'lon', })\n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "with benchmark('no loop'):\n",
    "    u = a.isel(channel=[1,3,4]).isel(lon=xarray.DataArray(i, dims=['sample']),\n",
    "                lat=xarray.DataArray(j, dims=['sample']))\n",
    "    print(u)\n",
    "    u = u.values\n",
    "    \n",
    "with benchmark('loop'):\n",
    "    v = []\n",
    "    for k, h in zip(i, j):\n",
    "        s = a.isel(channel=[1]).isel(lat=k).isel(lon=h).to_dataarray().values\n",
    "        v.append(s)\n",
    "    v = np.stack(v, axis=0)\n",
    "\n",
    "print(u.shape, v.shape)\n",
    "print((u==v).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c69bcdc-e89b-441f-9663-435d35141010",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= np.random.randint(0, 400, size=5000) # lon samples\n",
    "j = np.random.randint(0, 400, size=5000) # lat samples\n",
    "slice_i = [list(range(k, k+15)) for k in i]\n",
    "slice_j = [list(range(k, k+15)) for k in j]\n",
    "slice_i = xarray.DataArray(slice_i, dims=['sample', 'lat'])\n",
    "slice_j = xarray.DataArray(slice_j, dims=['sample', 'lon'])\n",
    "\n",
    "slice_ij, slice_ji = xarray.broadcast(slice_i, slice_j) # to sample x lat x lon and sample x lon x lat\n",
    "\n",
    "\n",
    "a = sarah[['SIS','SID']].isel(time=0).load() # seviri like zarr dataset\n",
    "\n",
    "with benchmark('no loop'):\n",
    "    u = a.isel(lon=slice_ij,\n",
    "                lat=slice_ji,).to_dataarray().values\n",
    "    \n",
    "with benchmark('loop'):\n",
    "    v = []\n",
    "    X = []\n",
    "    for i in range(len(i)):\n",
    "        X_ = a.isel(lat=slice_i[i],\n",
    "                    lon=slice_j[i]).to_dataarray().values\n",
    "        X.append(np.expand_dims(X_, 1))\n",
    "    X = np.concatenate(X, axis = 1)\n",
    "print(u.shape, X.shape)\n",
    "print((u==X).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b288e-7d37-4a14-9247-880d4f599700",
   "metadata": {},
   "source": [
    "# dataset testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14feec28-7c77-4530-ad89-be6028457916",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeviriDataset(\n",
    "    x_vars=config.x_vars,\n",
    "    y_vars=config.y_vars,\n",
    "    x_features=config.x_features,\n",
    "    patch_size=config.patch_size,\n",
    "    transform=config.transform,\n",
    "    target_transform=config.target_transform,\n",
    "    patches_per_image=1000,\n",
    "    seed =0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3f8676f-7923-44de-9865-c0e457f0c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, x, y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a1b69e9-72a7-4c39-a1c1-b0bf9e1f45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, x2, y2 = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a36126-84dd-4a25-af58-f297832f458d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y==y2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a50b4-1924-4e60-a89b-7e12a53b7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with benchmark('asdf'):\n",
    "    X, x, y = dataset[0]\n",
    "    print(X, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37574948-6489-4fb3-b313-687de5221400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    \n",
    "\n",
    "    X= torch.concat([x[0] for x in batch], dim=0)\n",
    "    x= torch.concat([x[1] for x in batch], dim=0)\n",
    "    y= torch.concat([x[2] for x in batch], dim=0)\n",
    "    return X, x, y\n",
    "\n",
    "dl = DataLoader(dataset, batch_size =None, num_workers =1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c741e-efaa-445a-9880-b0a046c18c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, x, y in tqdm(dl):\n",
    "    print(X.shape, x.shape, y.shape)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf1419-c588-43a5-80bc-ef0dea087c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = ['CAB', ]#'CAR', 'CEN' ,'MIL', 'NOR', 'PAL', 'PAY', 'TAB', 'TOR', 'VIS']\n",
    "\n",
    "test_datasets = [GroundstationDataset(nm, \n",
    "                                config.y_vars, \n",
    "                                config.x_vars, \n",
    "                                config.x_features, \n",
    "                                patch_size=config.patch_size['x'],\n",
    "                                transform=config.transform,\n",
    "                                target_transform=config.target_transform) \n",
    "            for nm in stations] \n",
    "\n",
    "test_dataloaders = {nm: DataLoader(ds, batch_size=10000, shuffle=False) for nm, ds in zip(stations, test_datasets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8e859-5ece-447b-880c-430119b2cb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning-kernel",
   "language": "python",
   "name": "lightning-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
