{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from dataset.dataset import SeviriDataset, pickle_read, MemmapSeviriDataset\n",
    "from dataset.station_dataset import GroundstationDataset\n",
    "from dataset.normalization import ZeroMinMax\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.utilities import rank_zero_only\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from models.LightningModule import LitEstimatorPoint\n",
    "from tqdm import tqdm\n",
    "import xarray\n",
    "\n",
    "# from pytorch_lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from train import get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 512,\n",
    "    \"patch_size\": {\n",
    "        \"x\": 15,\n",
    "        \"y\": 15,\n",
    "        \"stride_x\": 1,\n",
    "        \"stride_y\": 1,\n",
    "    },\n",
    "    \"x_vars\": [\n",
    "        \"channel_1\",\n",
    "        \"channel_2\",\n",
    "        \"channel_3\",\n",
    "        \"channel_4\",\n",
    "        \"channel_5\",\n",
    "        \"channel_6\",\n",
    "        \"channel_7\",\n",
    "        \"channel_8\",\n",
    "        \"channel_9\",\n",
    "        \"channel_10\",\n",
    "        \"channel_11\",\n",
    "        \"DEM\",\n",
    "    ],\n",
    "    \"y_vars\": [\"SIS\"],\n",
    "    \"x_features\": [\"dayofyear\", \"lat\", \"lon\", 'SZA', \"AZI\"],\n",
    "    \"transform\": ZeroMinMax(),\n",
    "    \"target_transform\": ZeroMinMax(),\n",
    "    # Compute related\n",
    "    'ACCELERATOR': \"gpu\",\n",
    "    'DEVICES': -1,\n",
    "    'NUM_NODES': 1,\n",
    "    # 'STRATEGY': \"ddp\",\n",
    "    'PRECISION': \"32\",\n",
    "    'num_workers':24,\n",
    "    'val_check_interval': 0.1,\n",
    "}\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/14 [00:02<00:33,  2.54s/it]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:03<00:19,  1.61s/it]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:04<00:13,  1.26s/it]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:05<00:12,  1.24s/it]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:06<00:10,  1.20s/it]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:07<00:08,  1.07s/it]\u001b[A\n",
      " 50%|█████     | 7/14 [00:08<00:07,  1.07s/it]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:10<00:07,  1.27s/it]\u001b[A\n",
      " 64%|██████▍   | 9/14 [00:11<00:05,  1.15s/it]\u001b[A\n",
      " 71%|███████▏  | 10/14 [00:12<00:04,  1.15s/it]\u001b[A\n",
      " 79%|███████▊  | 11/14 [00:13<00:03,  1.20s/it]\u001b[A\n",
      " 86%|████████▌ | 12/14 [00:15<00:02,  1.28s/it]\u001b[A\n",
      " 93%|█████████▎| 13/14 [00:15<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 14/14 [00:16<00:00,  1.21s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# train_dataset = SeviriDataset(\n",
    "#     x_vars=config.x_vars,\n",
    "#     y_vars=config.y_vars,\n",
    "#     x_features=config.x_features,\n",
    "#     patch_size=config.patch_size,\n",
    "#     transform=config.transform,\n",
    "#     target_transform=config.target_transform,\n",
    "#     patches_per_image=config.batch_size,\n",
    "#     validation=False,\n",
    "# )\n",
    "train_dataset = MemmapSeviriDataset()\n",
    "valid_dataset = SeviriDataset(\n",
    "    x_vars=config.x_vars,\n",
    "    y_vars=config.y_vars,\n",
    "    x_features=config.x_features,\n",
    "    patch_size=config.patch_size,\n",
    "    transform=config.transform,\n",
    "    target_transform=config.target_transform,\n",
    "    patches_per_image=2048,\n",
    "    validation=True,\n",
    ")\n",
    "\n",
    "zarr_fns = glob('../../ZARR/IEA_PVPS/IEA_PVPS_*.zarr')\n",
    "station_names_bsrn = [os.path.basename(fn).split('IEA_PVPS_')[-1].split('.')[0] for fn in zarr_fns]\n",
    "bsrn_datasets = [GroundstationDataset(f'../../ZARR/IEA_PVPS/IEA_PVPS_{x}.zarr', \n",
    "                                        config.y_vars, config.x_vars, config.x_features, config.patch_size['x'], \n",
    "                                        config.transform, config.target_transform)\n",
    "                            for x in tqdm(station_names_bsrn)]\n",
    "bsrn_dataset = torch.utils.data.ConcatDataset(bsrn_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightning import LightningDataModule\n",
    "\n",
    "\n",
    "class DataModule(LightningDataModule):\n",
    "\n",
    "  def __init__(self, train_dataset, val_dataset,  bsrn_dataset, batch_size):\n",
    "\n",
    "    super(DataModule, self).__init__()\n",
    "    self.train_dataset = train_dataset\n",
    "    self.val_dataset = val_dataset\n",
    "    self.bsrn_dataset = bsrn_dataset\n",
    "    self.num_dataloaders = 1\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size = None, shuffle = True, num_workers=12)\n",
    "  \n",
    "  def val_dataloader(self):\n",
    "    # val_loader1 = DataLoader(self.val_dataset, batch_size = None, shuffle = False, num_workers=config.num_workers)\n",
    "    val_loader2 = DataLoader(self.bsrn_dataset, batch_size = 4096, shuffle = False, num_workers=config.num_workers)\n",
    "    return [val_loader2]\n",
    "\n",
    "dm = DataModule(train_dataset, valid_dataset, bsrn_dataset, config.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240618_093511-k96nic20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/krschuurman/SIS_point_estimation/runs/k96nic20' target=\"_blank\">final</a></strong> to <a href='https://wandb.ai/krschuurman/SIS_point_estimation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/krschuurman/SIS_point_estimation' target=\"_blank\">https://wandb.ai/krschuurman/SIS_point_estimation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/krschuurman/SIS_point_estimation/runs/k96nic20' target=\"_blank\">https://wandb.ai/krschuurman/SIS_point_estimation/runs/k96nic20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/snx3000/kschuurm/lightning-env/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/snx3000/kschuurm/lightning-env/lib/python3. ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping('val_loss', patience=10, mode='min')\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(name='final', project=\"SIS_point_estimation\", log_model=True)\n",
    "\n",
    "if rank_zero_only.rank == 0:  # only update the wandb.config on the rank 0 process\n",
    "    wandb_logger.experiment.config.update(vars(config))\n",
    "\n",
    "mc_sarah = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    every_n_epochs=1, save_top_k = 3,\n",
    "    save_last=True,\n",
    ") \n",
    "\n",
    "\n",
    "trainer_sarah = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=config.ACCELERATOR,\n",
    "    devices=config.DEVICES,\n",
    "    min_epochs=1,\n",
    "    max_epochs=15,\n",
    "    precision=config.PRECISION,\n",
    "    log_every_n_steps=1000,\n",
    "    val_check_interval=config.val_check_interval,\n",
    "    callbacks=[early_stopping, mc_sarah],\n",
    "    max_time=\"00:03:50:00\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "\n",
    "estimator = LitEstimatorPoint(\n",
    "    config=config,\n",
    "    learning_rate=1e-6,\n",
    "    metric=MeanSquaredError()\n",
    ")\n",
    "\n",
    "trainer_sarah.fit(\n",
    "    estimator, dm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.432 MB of 0.432 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_step</td><td>▃▁▅▄▃▄▂█▇▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▂▂▃▄▅▅▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss_step</td><td>0.20192</td></tr><tr><td>trainer/global_step</td><td>5499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">final</strong> at: <a href='https://wandb.ai/krschuurman/SIS_point_estimation/runs/rr0f5r37' target=\"_blank\">https://wandb.ai/krschuurman/SIS_point_estimation/runs/rr0f5r37</a><br/>Synced 5 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240618_092023-rr0f5r37/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger.experiment.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning-kernel2",
   "language": "python",
   "name": "lightning-kernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
