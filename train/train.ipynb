{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import wandb\n",
    "import xarray\n",
    "from dataset.dataset import ImageDataset, valid_test_split, SeviriDataset\n",
    "from dataset.station_dataset import GroundstationDataset\n",
    "from dataset.normalization import MinMax, ZeroMinMax\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.plugins.environments import SLURMEnvironment\n",
    "from lightning.pytorch.utilities import rank_zero_only\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from models.ConvResNet_Jiang import ConvResNet, ConvResNet_dropout\n",
    "from models.LightningModule import LitEstimator, LitEstimatorPoint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from pytorch_lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from utils.plotting import best_worst_plot, prediction_error_plot\n",
    "from utils.etc import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/snx3000/kschuurm/lightning/lib/python3.9/site-packages/distributed/node.py:182: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37387 instead\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"patch_size\": {\n",
    "        \"x\": 15,\n",
    "        \"y\": 15,\n",
    "        \"stride_x\": 10,\n",
    "        \"stride_y\": 10,\n",
    "    },\n",
    "    \"x_vars\": [\n",
    "        \"channel_1\",\n",
    "        \"channel_2\",\n",
    "        \"channel_3\",\n",
    "        \"channel_4\",\n",
    "        \"channel_5\",\n",
    "        \"channel_6\",\n",
    "        \"channel_7\",\n",
    "        \"channel_8\",\n",
    "        \"channel_9\",\n",
    "        \"channel_10\",\n",
    "        \"channel_11\",\n",
    "        \"DEM\",\n",
    "    ],\n",
    "    \"y_vars\": [\"SIS\"],\n",
    "    \"x_features\": [\"dayofyear\", \"lat\", \"lon\", 'SZA', \"AZI\"],\n",
    "    \"transform\": ZeroMinMax(),\n",
    "    \"target_transform\": ZeroMinMax(),\n",
    "    # Compute related\n",
    "    'ACCELERATOR': \"gpu\",\n",
    "    'DEVICES': -1,\n",
    "    'NUM_NODES': 1,\n",
    "    # 'STRATEGY': \"ddp\",\n",
    "    'PRECISION': \"32\",\n",
    "}\n",
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sarah_bnds = xarray.open_zarr('/scratch/snx3000/kschuurm/ZARR/SARAH3_bnds.zarr').load()\n",
    "sarah_bnds = sarah_bnds.isel(time = sarah_bnds.pixel_count != -1)\n",
    "seviri = xarray.open_zarr(\"/scratch/snx3000/kschuurm/ZARR/SEVIRI_new.zarr\")\n",
    "seviri_time = pd.DatetimeIndex(seviri.time)\n",
    "timeindex= pd.DatetimeIndex(sarah_bnds.time)\n",
    "timeindex = timeindex.intersection(seviri_time)\n",
    "timeindex = timeindex[(timeindex.hour >10) & (timeindex.hour <17)]\n",
    "\n",
    "traintimeindex = timeindex[(timeindex.year == 2016)]\n",
    "_, validtimeindex = valid_test_split(timeindex[(timeindex.year == 2017)])\n",
    "\n",
    "train_dataset = SeviriDataset(\n",
    "    x_vars=config.x_vars,\n",
    "    y_vars=config.y_vars,\n",
    "    x_features=config.x_features,\n",
    "    patch_size=config.patch_size,\n",
    "    transform=config.transform,\n",
    "    target_transform=config.target_transform,\n",
    "    patches_per_image=2048,\n",
    "    timeindices=traintimeindex,\n",
    ")\n",
    "valid_dataset = SeviriDataset(\n",
    "    x_vars=config.x_vars,\n",
    "    y_vars=config.y_vars,\n",
    "    x_features=config.x_features,\n",
    "    patch_size=config.patch_size,\n",
    "    transform=config.transform,\n",
    "    target_transform=config.target_transform,\n",
    "    patches_per_image=1024,\n",
    "    timeindices=validtimeindex,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvResNet(\n",
    "    num_attr=len(config.x_features),\n",
    "    input_channels=len(config.x_vars),\n",
    "    output_channels=len(config.y_vars),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/snx3000/kschuurm/lightning/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/scratch/snx3000/kschuurm/lightning/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/snx3000/kschuurm/lightning/lib/python3.9/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping('val_loss')\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"SIS_point_estimation\", log_model=True)\n",
    "\n",
    "if rank_zero_only.rank == 0:  # only update the wandb.config on the rank 0 process\n",
    "    wandb_logger.experiment.config.update(vars(config))\n",
    "\n",
    "mc_station = ModelCheckpoint(\n",
    "    every_n_epochs=10, save_top_k = -1\n",
    ")\n",
    "mc_sarah = ModelCheckpoint(\n",
    "    every_n_epochs=1, save_top_k = -1\n",
    ") \n",
    "\n",
    "# trainer_station = Trainer(\n",
    "#     # profiler=\"simple\",\n",
    "#     # fast_dev_run=True,\n",
    "#     # num_sanity_val_steps=2,\n",
    "#     logger=wandb_logger,\n",
    "#     accelerator=ACCELERATOR,\n",
    "#     devices=DEVICES,\n",
    "#     min_epochs=1,\n",
    "#     max_epochs=100,\n",
    "#     precision=PRECISION,\n",
    "#     log_every_n_steps=500,\n",
    "#     check_val_every_n_epoch=5,\n",
    "#     callbacks=[early_stopping, mc],\n",
    "# )\n",
    "\n",
    "\n",
    "trainer_sarah = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=config.ACCELERATOR,\n",
    "    devices=config.DEVICES,\n",
    "    min_epochs=1,\n",
    "    max_epochs=35,\n",
    "    precision=config.PRECISION,\n",
    "    log_every_n_steps=500,\n",
    "    # val_check_interval=1,\n",
    "    callbacks=[early_stopping, mc_sarah],\n",
    "    max_time=\"00:02:00:00\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders = DataLoader(train_dataset, shuffle=True, batch_size=None, num_workers=0)\n",
    "valid_dataloaders = DataLoader(valid_dataset, shuffle=False, batch_size=None, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = LitEstimatorPoint(\n",
    "    model=model,\n",
    "    learning_rate=0.0001,\n",
    "    config=config,\n",
    ")\n",
    "trainer_sarah.fit(\n",
    "    estimator, train_dataloaders=train_dataloaders, val_dataloaders=valid_dataloaders,\n",
    "    # ckpt_path='/scratch/snx3000/kschuurm/irradiance_estimation/train/SIS_point_estimation/tt2pie1v/checkpoints/epoch=30-step=4020.ckpt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = ['CAB', 'CAR', 'CEN' ,'MIL', 'NOR', 'PAL', 'PAY', 'TAB', 'TOR', 'VIS']\n",
    "\n",
    "test_datasets = [GroundstationDataset(nm, \n",
    "                                      config.y_vars, \n",
    "                                      config.x_vars, \n",
    "                                      config.x_features, \n",
    "                                      patch_size=15,\n",
    "                                      transform=config.transform,\n",
    "                                      target_transform=config.target_transform) \n",
    "                 for nm in stations] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "\n",
    "train_ds, valid_ds = random_split(test_dataset, [0.7, 0.3])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=2048, shuffle=True, num_workers= 5)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=2048, shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LitEstimatorPoint(\n",
    "    model=model,\n",
    "    learning_rate=0.001,\n",
    "    config=config,\n",
    ")\n",
    "trainer.fit(\n",
    "    estimator, train_dataloaders=train_dl, val_dataloaders=valid_dl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=10000, shuffle=False, num_workers=0\n",
    ")\n",
    "trainer.test(dataloaders=test_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning-kernel",
   "language": "python",
   "name": "lightning-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
